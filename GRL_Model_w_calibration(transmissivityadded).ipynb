{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRL_Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iordach1/GEOL572-GRL/blob/master/GRL_Model_w_calibration(transmissivityadded).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4KWGGv5A7F2",
        "colab_type": "text"
      },
      "source": [
        "# <center>FloPy Regional Model Development</center>\n",
        "The following script develops a regional MODFLOW model using FloPy and associated packages. The study domain is the Mahomet Aquifer in Illinois, particulary in the heavily irrigated region of Mason County. \n",
        "\n",
        "Note that you may not always have to compile MODFLOW, and you only have initialize code (#1) and import large files (#2) the first time you run the code in a session. Most of the time, you will only have to run #3 onward. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZeCuFvptP_f",
        "colab_type": "text"
      },
      "source": [
        "# 0. Compile MODFLOW (DO NOT RUN UNLESS NECESSARY)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0WdSEtOElwW",
        "colab_type": "text"
      },
      "source": [
        "When using Google CoLab, you cannot simply use an existing MODFLOW executable, but have to compile a a new one for use in this environment. I have already compiled MODFLOW, but am currently unsure if it will work for everybody. Please do not run the following code unless you get an error that the MODFLOW file was not found (will occur when running the model). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Imxy2VTEuFWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install https://github.com/modflowpy/pymake/zipball/master # install of the pymake package to compile MODFLOW"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GRcmZ0Oudvp1",
        "colab": {}
      },
      "source": [
        "# Code to compile the MODFLOW executable\n",
        "\n",
        "#import pymake\n",
        "\n",
        "#def make_mf2005():\n",
        "#    pymake.build_apps('mf2005')\n",
        "\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "#    make_mf2005()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#import pymake\n",
        "\n",
        "#def make_mfnwt():\n",
        "#    pymake.build_apps('mfnwt')\n",
        "\n",
        "#if __name__ == \"__main__\":\n",
        "#    make_mfnwt()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Wf-e4N6BUJo",
        "colab_type": "text"
      },
      "source": [
        "# 1 Initializing the code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3dybMuFEr1q",
        "colab_type": "text"
      },
      "source": [
        "These few code blocks only have to be run at the beginning of the script or if a runtime connection is lost. See details for each below. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiQlOJosBqXy",
        "colab_type": "text"
      },
      "source": [
        "## 1A. Install needed packages\n",
        "There are three packages that must be installed in the CoLab environment to run this script. These include \n",
        "\n",
        "\"pyproj\", which allows for the conversion from WGS84 coordinates (as obtained from Google Earth), which are in lat/long decimal degrees, to Illimap coordinates, a specialized projection using Lambert Conformal Conic that is optimized for developing a model grid in the state of Illinois. \n",
        "\n",
        "\"flopy\" creates modflow executables, runs the model, and allows for manipulation of results.\n",
        "\n",
        "\"rasterio\" allows for the reading of raster files, and is closely tied to the development of \"flopy\" input files\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z0rwRhzkGuf3",
        "colab": {}
      },
      "source": [
        "#Get the EEG, the BP monitor, and the AVV.\n",
        "!pip install pyproj\n",
        "!pip install flopy\n",
        "!pip install rasterio\n",
        "!pip install pykrige\n",
        "!pip install metpy\n",
        "!apt-get -qq install python-cartopy python3-cartopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6tMviUVufyx",
        "colab_type": "text"
      },
      "source": [
        "## 1B. Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "It0QTEJCQCuV",
        "colab": {}
      },
      "source": [
        "#And get the machine that goes 'ping!'.\n",
        "import flopy # import flopy to develop, run, and analyze the model\n",
        "from flopy.utils import Raster # plot rasters from flopy\n",
        "import matplotlib as mp\n",
        "import pandas as pd\n",
        "import pyproj # change between WGS84 and Illimap coordinates\n",
        "import rasterio  # import rasters\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.lines as mlines\n",
        "import numpy as np \n",
        "import json\n",
        "import math\n",
        "import cartopy\n",
        "import cartopy.crs as ccrs # import projections\n",
        "import cartopy.feature as cf # import features\n",
        "from pykrige.uk import UniversalKriging\n",
        "import pylab # using as a plotting library for spatial data, make contours\n",
        "from metpy.plots import USCOUNTIES\n",
        "\n",
        "#And get the most expensive machine - in case the Administrator comes.\n",
        "# the following code authorizes you to access files on Google Drive\n",
        "from google.colab import drive, files, auth\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from oauth2client.client import GoogleCredentials\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRFZ3O-TurE2",
        "colab_type": "text"
      },
      "source": [
        "## 1C. Authenticate with Google\n",
        "This will allow you to access shared files on my Google Drive or your own. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hstJX5XhPT9r",
        "colab": {}
      },
      "source": [
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoUf-0HKvAUm",
        "colab_type": "text"
      },
      "source": [
        "## 1D. Read the MODFLOW executable from Google Drive\n",
        "\n",
        "Here you are going to download the MODFLOW executable from Daniel's Google Drive. This will show up in your temporary working directory for use later in the code. <b>We need to confirm whether this will work in CoLab, or if you need to compile a new version of MODFLOW each time.</b>\n",
        "\n",
        "Note that this makes use of a key on your Google Drive sharable link for the file. This generally takes the form of: https://drive.google.com/file/d/**key**/view?usp=sharing, in this case, key = 1SwqsSCvyrnrCiopeEp52LBcZYNcgBT9V"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NITzYdM_PgFM",
        "colab": {}
      },
      "source": [
        "downloaded = drive.CreateFile({'id':\"1SwqsSCvyrnrCiopeEp52LBcZYNcgBT9V\"}) # This is the key that is defined in the shareable link of a file on Google Drive\n",
        "downloaded.GetContentFile('mf2005') # get the content from Google Drive and name it (let's stick with mf2005 here)\n",
        "\n",
        "#downloaded = drive.CreateFile({'id':\"1iThxRoGVhofLPd8HOF7Vn0awRVrXZcVb\"}) # This is the key that is defined in the shareable link of a file on Google Drive\n",
        "#downloaded.GetContentFile('mfnwt') # get the content from Google Drive and name it (let's stick with mf2005 here)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-owARmIvCoH",
        "colab_type": "text"
      },
      "source": [
        "Now we need to copy the executable into a location where we can later run it. Note that the \"!\" nomenclature is a shell command, beyond the scope of this course to learn that!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9WK5wZAzjdna",
        "colab": {}
      },
      "source": [
        "!cp mf2005 /usr/local/bin\n",
        "!chmod 755 /usr/local/bin/mf2005\n",
        "\n",
        "#!cp mfnwt /usr/local/bin\n",
        "#!chmod 755 /usr/local/bin/mfnwt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oywHJyvfxXAq",
        "colab_type": "text"
      },
      "source": [
        "# 2 Import the big stuff\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bd7Rk7IlD3Ra",
        "colab_type": "text"
      },
      "source": [
        "We don't want to repeatedly import large files for fear of Google revoking our CoLab priveleges for a few hours. Once or twice isn't a big deal, but repeatedly might be an issue. Let Daniel know if this happens- there are ways to reduce our file sizes. \n",
        "\n",
        "For now, the \"big stuff\" includes a DEM of Illinois and the river excel file we worked with last time. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7W_2AeFMx4Ai",
        "colab_type": "text"
      },
      "source": [
        "## 2A. Import the DEM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3ygMVkWFAcWv",
        "colab": {}
      },
      "source": [
        "# first import the land surface .tif from Google Drive\n",
        "downloaded = drive.CreateFile({'id':\"1389l8sgQ8-tsmIZuZosaqvbqpHY40n6l\"}) # ft above msl, works best for most groups, spiky in Mason County \n",
        "downloaded.GetContentFile('landsurface_el.tif')\n",
        "\n",
        "# first import the bedrock elevation .tif from Google Drive\n",
        "downloaded = drive.CreateFile({'id':\"1EZgZDjjILzvRzvY9nf0Qp0NHmspRq4kP\"})   \n",
        "downloaded.GetContentFile('bedrock_el.tif')\n",
        "\n",
        "# read in percent thickness of coarse grain for each model layer\n",
        "downloaded = drive.CreateFile({'id':\"18Kw3O6qCzIJ2L6KrVnRPIhea_F8VwyWn\"})   \n",
        "downloaded.GetContentFile('percentl1.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1oZinFPKrGY-FXoE7Zu0okFpAAOe_bwau\"})   \n",
        "downloaded.GetContentFile('percentl2.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1FqVEr4m_ElUyEZeyfnCMwVGDfUqavJZH\"})   \n",
        "downloaded.GetContentFile('percentl3.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1KiHS9TLSP1GAVTjaaJZS4BAwF6gnUeDu\"})   \n",
        "downloaded.GetContentFile('percentl4.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1Z-9EyaAK1NKnRHAlnyGYkI3suvBFC2I6\"})   \n",
        "downloaded.GetContentFile('percentl5.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1pcB9aJpJGfkXOKz10rhs6MpWkQL1_dqr\"})   \n",
        "downloaded.GetContentFile('percentl6.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1Fnh0HIKbUj7pEtlsUKR_Sr7WwfYzWul5\"})   \n",
        "downloaded.GetContentFile('percentl7.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"106JacgpwSA3wVAGcBIzGdc8rDVUB6dh7\"})   \n",
        "downloaded.GetContentFile('percentl8.tif')\n",
        "\n",
        "downloaded = drive.CreateFile({'id':\"1WJjhVJ_KSBhZDrgzY3YteNjxaz5nxBid\"})   \n",
        "downloaded.GetContentFile('percentl9.tif')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqxp3yqCydpY",
        "colab_type": "text"
      },
      "source": [
        "## 2B. Import the river file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VqaFoQiu7tP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first import the Excel file from Google Drive\n",
        "downloaded = drive.CreateFile({'id':\"1JsAiGG4RvcfYrQtfgXRW9ZVfAkQ1yRVu\"})\n",
        "downloaded.GetContentFile('rivers_625.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OROiooZxzUuH",
        "colab_type": "text"
      },
      "source": [
        "# 3 Create MODFLOW  packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-uLI2Rf0PIw",
        "colab_type": "text"
      },
      "source": [
        "## 3A. Model Set-up"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnPkGXMG0qdv",
        "colab_type": "text"
      },
      "source": [
        "### 3Ai. Define the Model Domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xKgi6FiwSwY0",
        "colab": {}
      },
      "source": [
        "#----------------------------------------------------------------------------\n",
        "'''GRL'''\n",
        "sw_lat =  41.2 #southwest latitude\n",
        "sw_long = -90.5 #southwest longitude\n",
        "ne_lat =  41.9 #northeast latitude\n",
        "ne_long = -89.2 #northeast longitude\n",
        "\n",
        "illimap = {'proj': 'lcc', # Lambert Conformal Conic\n",
        "     'ellps': 'clrk66',\n",
        "     'lon_0': -89.5,\n",
        "     'lat_0': 33,\n",
        "     'lat_1': 33,\n",
        "     'lat_2': 45,\n",
        "     'x_0': 2999994*0.3048,\n",
        "     'y_0': 0}\n",
        "\n",
        "prj = pyproj.Proj(illimap)\n",
        "\n",
        "wgs84 = pyproj.Proj(\"epsg:4326\")\n",
        "\n",
        "nex, ney = pyproj.transform(wgs84,illimap,ne_lat,ne_long)\n",
        "swx, swy = pyproj.transform(wgs84,illimap,sw_lat,sw_long)\n",
        "\n",
        "nex, ney = round(nex/0.3048,-4), round(ney/0.3048,-4)\n",
        "swx, swy = round(swx/0.3048,-4), round(swy/0.3048,-4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpselZ1G2hoC",
        "colab_type": "text"
      },
      "source": [
        "### 3Aii. Define spatial and temporal discretization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JZPmYy-DkqGy",
        "colab": {}
      },
      "source": [
        "# Assign Discretization variables\n",
        "Lx = nex-swx # Width of the model domain\n",
        "Ly = ney-swy # Height of the model domain\n",
        "nlay = 10 # Number of model layers\n",
        "dx = 2000 \n",
        "dy = 2000\n",
        "nrow = int(Ly/dy) # Number of rows\n",
        "ncol = int(Lx/dx) # Number of columns\n",
        "\n",
        "nper = 1 #specify number of stress periods\n",
        "steady = [True] #specify if stress period is transient or steady-state\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoUbGJMb0e2Q",
        "colab_type": "text"
      },
      "source": [
        "### 3Aiii. Define river elevations\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCZvnOQm05ww",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import stage, lambert x, lambert y\n",
        "dfriv = pd.read_csv('rivers_625.csv')\n",
        "\n",
        "# trim dataframe with river information to the model domain\n",
        "dfriv = dfriv.loc[dfriv['lamx']<nex]\n",
        "dfriv = dfriv.loc[dfriv['lamy']<ney]\n",
        "dfriv = dfriv.loc[dfriv['lamx']>swx]\n",
        "dfriv = dfriv.loc[dfriv['lamy']>swy]\n",
        "\n",
        "# assign all rivers to the upper layer\n",
        "dfriv['lay'] = 0\n",
        "# convert lamx to column and lamy to row\n",
        "dfriv['row'] = np.trunc((ney-dfriv['lamy'])/dy)\n",
        "dfriv['col'] = np.trunc((dfriv['lamx']-swx)/dx)\n",
        "# define the river stage\n",
        "dfriv['stage'] = dfriv['rvr_stg']\n",
        "#define the conductance\n",
        "dfriv['cond'] = 5000. # ft^2/d\n",
        "# define the river bottom\n",
        "dfriv['bot'] = dfriv['stage']-3\n",
        "# drop unneeded files\n",
        "dfriv = dfriv.drop(['STR_ORD_MI','STR_ORD_MA','SUM_LENGTH','rvr_stg','lamx','lamy'],axis=1)\n",
        "\n",
        "dfriv = dfriv.groupby(['lay','row','col'],as_index=False).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMLXmXKF838v",
        "colab_type": "text"
      },
      "source": [
        "### 3Aiv. Define top and bottom elevations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sv1P7Bg8-RF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now load the raster using FloPy's built in Raster toolbox\n",
        "illinoisdem = Raster.load(\"landsurface_el.tif\")\n",
        "bedrock = Raster.load(\"bedrock_el.tif\")\n",
        "\n",
        "# Crop the dEM to the model domain\n",
        "illinoisdem.crop([(swx,swy),(swx,ney),(nex,ney),(nex,swy)])\n",
        "bedrock.crop([(swx,swy),(swx,ney),(nex,ney),(nex,swy)])\n",
        "# Define centroid of the southwestern most cell\n",
        "startx = swx+dx/2 \n",
        "starty = swy+dx/2\n",
        "# Calculate the x and y coordinates for the centroid of each cell \n",
        "xc = np.arange(swx+dx/2,nex+dx/2,dx) \n",
        "yc = np.arange(swy+dy/2,ney+dy/2,dy)\n",
        "# Create a grid of the x coordinate of each centroid and the y coordinate\n",
        "xarr, yarr = np.meshgrid(xc,yc)\n",
        "# resample the topo raster to the grid of centroids of the model\n",
        "topgrid = illinoisdem.resample_to_grid(xarr,yarr,1,method='nearest') \n",
        "bedrock = bedrock.resample_to_grid(xarr,yarr,1,method='nearest')\n",
        "\n",
        "# We just built our top elevation upside down, let's flip it\n",
        "topgrid = np.flipud(topgrid) \n",
        "bedrockgrid = np.flipud(bedrock)   \n",
        "\n",
        "# the grid does not extend past the boundaries of Illinois\n",
        "# the following code is for groups working in the western part of the state\n",
        "maxrow = topgrid.shape[0]\n",
        "maxcol = topgrid.shape[1]\n",
        "\n",
        "# Create ibound as array of ints (1), indicating all cells are active\n",
        "# inactivate cells west of the Mississippi River that were originally not present\n",
        "# note that because inactive cells would overlap with the river boundaries, this code pushes inactive cells to the west a bit. Adjust per your model domain\n",
        "ibound = np.ones((nlay, nrow, ncol), dtype=np.int32)\n",
        "\n",
        "for row in np.arange(maxrow,0,-1):\n",
        "  counter = 0\n",
        "  for col in np.arange(maxcol,0,-1):\n",
        "    if topgrid[row-1,col-1] <= 0:\n",
        "      counter = counter+1\n",
        "      topgrid[row-1,col-1] = topgrid[row-1,col]\n",
        "      bedrockgrid[row-1,col-1] = bedrockgrid[row-1,col]\n",
        "      if counter>=4:\n",
        "        ibound[:,row-1,col-1] = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Set the top of Layer 1 = River Elevation\n",
        "for index, row in dfriv.iterrows():  \n",
        "    topgrid[int(row['row']),int(row['col'])]=row['stage'] \n",
        "    #print(topgrid[int(row['row']),int(row['col'])],row['bot'])  \n",
        "\n",
        "# make sure that all layers are at least 9 ft thick\n",
        "diff = topgrid-bedrockgrid\n",
        "\n",
        "diff[diff<=9.0] = 9.0\n",
        "\n",
        "# each layer is the same thickness, we need 9 glacial layers\n",
        "laythick = diff/9\n",
        "\n",
        "#calculate bottom of each layer\n",
        "lay1bot = topgrid-laythick\n",
        "lay2bot = topgrid-2*laythick\n",
        "lay3bot = topgrid-3*laythick\n",
        "lay4bot = topgrid-4*laythick\n",
        "lay5bot = topgrid-5*laythick\n",
        "lay6bot = topgrid-6*laythick\n",
        "lay7bot = topgrid-7*laythick\n",
        "lay8bot = topgrid-8*laythick\n",
        "lay9bot = topgrid-9*laythick\n",
        "lay10bot = lay9bot-50.\n",
        "\n",
        "botgrids = [lay1bot,lay2bot,lay3bot,lay4bot,lay5bot,lay6bot,lay7bot,lay8bot,lay9bot,lay10bot]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDDlICg0Jqiv",
        "colab_type": "text"
      },
      "source": [
        "### 3Av. Assign hydraulic conductivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2PuBykRIb7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# assign hydraulic conductivity in ft/day\n",
        "kc = 240 # predominantly coarse\n",
        "kf = .0013 # predominantly fine\n",
        "kb = 20 # bedrock\n",
        "\n",
        "# determine how to assign hydraulic conductivity\n",
        "threshold = 52 # anything above this will be assigned kc and below kf\n",
        "\n",
        "def kloader(rastername, kc, kf, threshold):\n",
        "  percent = Raster.load(rastername) # load raster\n",
        "  percent.crop([(swx,swy),(swx,ney),(nex,ney),(nex,swy)]) # crop array\n",
        "  percentgrid = percent.resample_to_grid(xarr,yarr,1,method='nearest') # resample to model grid\n",
        "  percentgrid = np.flipud(percentgrid) # flip the grid\n",
        "  maxrow = percentgrid.shape[0]\n",
        "  maxcol = percentgrid.shape[1]\n",
        "  for row in np.arange(maxrow,0,-1):\n",
        "    for col in np.arange(maxcol,0,-1):\n",
        "      if percentgrid[row-1,col-1] < -10:\n",
        "        percentgrid[row-1,col-1] = percentgrid[row-1,col]\n",
        "  percentgrid[percentgrid>=threshold] = kc # assign coarse k value\n",
        "  percentgrid[percentgrid<threshold] = kf # assign fine k value\n",
        "  return percentgrid\n",
        "\n",
        "kl1 = kloader('percentl1.tif',kc,kf,threshold)\n",
        "kl2 = kloader('percentl2.tif',kc,kf,threshold)\n",
        "kl3 = kloader('percentl3.tif',kc,kf,threshold)\n",
        "kl4 = kloader('percentl4.tif',kc,kf,threshold)\n",
        "kl5 = kloader('percentl5.tif',kc,kf,threshold)\n",
        "kl6 = kloader('percentl6.tif',kc,kf,threshold)\n",
        "kl7 = kloader('percentl7.tif',kc,kf,threshold)\n",
        "kl8 = kloader('percentl8.tif',kc,kf,threshold)\n",
        "kl9 = kloader('percentl9.tif',kc,kf,threshold)\n",
        "kl10 = kl9-kl9+kb\n",
        "\n",
        "khlayers = [kl1,kl2,kl3,kl4,kl5,kl6,kl7,kl8,kl9,kl10]\n",
        "kvlayers=np.divide(khlayers,10.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6hQGwMpAntO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating calculations for Transmissivity - ft^2/day (same as that which was derived by Anthony as part of milestone 1)\n",
        "\n",
        "# because we know that each model layer is the same thickness [ft] and K [ft/day] is calculated above: \n",
        "\n",
        "tl1 = (kl1*laythick)\n",
        "tl2 = (kl2*laythick)\n",
        "tl3 = (kl3*laythick)\n",
        "tl4 = (kl4*laythick)\n",
        "tl5 = (kl5*laythick)\n",
        "tl6 = (kl6*laythick)\n",
        "tl7 = (kl7*laythick)\n",
        "tl8 = (kl8*laythick)\n",
        "tl9 = (kl9*laythick)\n",
        "tl10 = (kl10*laythick)\n",
        "\n",
        "\n",
        "Total = tl1+tl2+tl3+tl4+tl5+tl6+tl7+tl8+tl9+tl10\n",
        "\n",
        "Tmax = np.max(Total)\n",
        "Tmin = np.min(Total)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QoCKtXB3zoLH",
        "colab_type": "text"
      },
      "source": [
        "## 3B. Create the MODFLOW model object "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "-v2Uc_JWSsu1",
        "colab": {}
      },
      "source": [
        "# Create a MODFLOW model object and run with MODFLOW 2005.\n",
        "modelname = \"my_model\" # name the model\n",
        "m = flopy.modflow.Modflow(modelname, version = 'mf2005', exe_name = 'mf2005') # create model object m"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNkGlXTw0Y8_",
        "colab_type": "text"
      },
      "source": [
        "## 3C. Append the discretization package to the model object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_MSCNyTkknUU",
        "colab": {}
      },
      "source": [
        "# length and time are feet (1) and days (4).\n",
        "# See https://water.usgs.gov/ogw/modflow/MODFLOW-2005-Guide/index.html?dis.htm \n",
        "dis = flopy.modflow.ModflowDis(model=m, nlay=nlay, nrow=nrow, ncol=ncol, \n",
        "                               delr=dx, delc=dy, top=topgrid, botm=botgrids, \n",
        "                               itmuni = 4, lenuni = 1, \n",
        "                               nper=nper, steady=steady)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohZcMcra23lN",
        "colab_type": "text"
      },
      "source": [
        "## 3D. Basic Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "US3C3_-XS0gk",
        "colab": {}
      },
      "source": [
        "# Create ibound as array of ints (1), indicating all cells are active\n",
        "#ibound = np.ones((nlay, nrow, ncol), dtype=np.int32)\n",
        "\n",
        "#Create flopy bas object\n",
        "bas = flopy.modflow.ModflowBas(m, ibound=ibound, strt=topgrid)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PSnNO_x3RUj",
        "colab_type": "text"
      },
      "source": [
        "## 3E. LPF Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sMP89XUkS4lL",
        "colab": {}
      },
      "source": [
        "#define layer type as convertible (1), must be an integer\n",
        "#for more information, see https://water.usgs.gov/ogw/modflow/MODFLOW-2005-Guide/index.html?dis.htm\n",
        "laytyp = 0*np.ones((nlay,), dtype=np.int32)\n",
        "\n",
        "# create the LPF object\n",
        "lpf = flopy.modflow.ModflowLpf(model=m, hk=khlayers, vka=kvlayers, laytyp=laytyp, ipakcb=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blNu8BSC3VgJ",
        "colab_type": "text"
      },
      "source": [
        "## 3F. Boundary Conditions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4Y1btf03ivQ",
        "colab_type": "text"
      },
      "source": [
        "### 3Fi. Recharge Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gDZ98E8NS8UG",
        "colab": {}
      },
      "source": [
        "# It might be worthwhile to use the average recharge rate for the summer and a modified, higher recharge rate for non-summer.\n",
        "# According to Burch, observed recharge is greatest following the end of the growing season, presumably in the fall, since precipitation available for recharge is limited to just after the growing season\" (Burch, 2004).\n",
        "\n",
        "# Average recharge = 333,000 gpd/sq mi = 0.001597 ft/d (Burch, 2004)\n",
        "# For higher recharge rate, one option is to look at the water table fluctuation method and take the maximum recharge rate\n",
        "\n",
        "# Recharge for cells where low-k material is at the surface is guessed to be an order of magnitude less than the recharge rate for cells with high-k material at the surface.\n",
        "# The plan is to tinker with this assumption when we calibrate the model.\n",
        "\n",
        "rch_avg=0.001597 # high recharge rate, in ft/d\n",
        "\n",
        "# rch_low=rch_avg/10 # low recharge rate, in ft/d\n",
        "# The model did not converge with this initial guess for the recharge rate for cells with low-k material at land surface\n",
        "\n",
        "rch_low=rch_avg/2 # low recharge rate, in ft/d\n",
        "# The model converged with this recharge rate, but I'm concerned it may be inaccurate\n",
        "\n",
        "# Low-k material is at the surface in any cells where k=kf for layer #1 (kl1 = kf)\n",
        "# High-k material is at the surface in any cells where k=kc for layer #1 (kl1 = kc)\n",
        "\n",
        "# For cells where kl1 = kf, recharge is rch_low.\n",
        "# For cells where kl1 = kc, recharge is rch_avg.\n",
        "recharge=np.where(kl1<=kf,rch_low,rch_avg) # This line of code was made possible by the Will County group, and viewers like you!\n",
        "\n",
        "# Assign recharge to the model\n",
        "rch = flopy.modflow.mfrch.ModflowRch(model=m,nrchop=3,rech = recharge) # recharge rate is in ft/day"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-otcrtqA3ZTZ",
        "colab_type": "text"
      },
      "source": [
        "### 3Fii. River Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pwTDkxudTGmP",
        "colab": {}
      },
      "source": [
        "# put into a format that MODFLOW wants\n",
        "arriv = dfriv.values\n",
        "riverdata = {0: arriv}\n",
        "\n",
        "# create river package\n",
        "riv = flopy.modflow.mfriv.ModflowRiv(model=m,ipakcb=None,stress_period_data=riverdata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "197weMSqBiEu",
        "colab_type": "text"
      },
      "source": [
        "### 3Fiii. Drain Package\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R72J1xcUBgw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drain Package (DRN)\n",
        "# Used to simulate head-dependent flux boundaries.  If the head in a cell falls below a certain threshold, the flux from the drain cell to the model cell drops to zero.\n",
        "\n",
        "# Create an empty list as a starting point for our drain data\n",
        "# Here, \"ardrn\" will function similarly to \"arriv\" in the previous code block\n",
        "ardrn=[]\n",
        "\n",
        "# \"For\" loop to search through the kl1 array and assign a drain conductance to cells where low-k material is at the surface\n",
        "# Low-k material is at the surface in any cells where k=kf for the top layer (kl1=kf)\n",
        "for row in range(m.nrow):\n",
        "  for col in range(m.ncol):\n",
        "    if round(float(kl1[row][col]),5)==kf: # This \"if\" statement covers cells where low-k material is present at land surface\n",
        "      #C=kf*100*dx*dy/3 # C is the conductance between land surface and the drain, in ft^2/day.\n",
        "          \n",
        "      C=kf*10*dx*dy/3 # Tried reducing the conductance for the drain cells, to see if MODFLOW terminates normally.\n",
        "      # This worked, but I'm concerned the conductance is inaccurate.\n",
        "      \n",
        "      # For more information regarding the equation for conductance, see the \"notes on the conductance of drain cells\" comment below.\n",
        "      \n",
        "      # Append the drain array \"ardrn\" with a list corresponding to each cell to be added to the drain package\n",
        "      # Items in the drain array are lists with the format [Layer, Row, Column, Elevation, Conductance]\n",
        "      ardrn.append([0, row, col, topgrid[row][col], C])\n",
        "\n",
        "# Notes on the conductance of drain cells\n",
        "# C=K*dx*dy/delta ; C=K*dx*dy/b\n",
        "# K is the conductivity of the soil layer\n",
        "# delta or b is the thickness of the soil layer\n",
        "# Out of a handful of randomly selected well logs, the uppermost soil layer (where present) reached a depth anywhere from 1 to 5 feet.\n",
        "# For simplicity, the soil layer is assumed to have a thickness of 3 feet, uniform throughout the model.\n",
        "\n",
        "# From the FloPy documentation:\n",
        "# flopy.modflow.mfdrn.ModflowDrn(model, ipakcb=None, stress_period_data=None, dtype=None, extension='drn', unitnumber=None, options=None, filenames=None, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XnmxBzaLPEw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Drain Return Package (DRT)\n",
        "# Allows simulation of drains in which some of the water from the drain is used to recharge the aquifer\n",
        "\n",
        "# remove the drn package\n",
        "#m.remove_package('DRN')\n",
        "\n",
        "# create the drt package\n",
        "#spd=[]\n",
        "#for i in range(m.nrow):\n",
        "    #spd.append([0, i, m.ncol-1, 5.0, 50.0, 1, 1, 1, 1.0])\n",
        "#d = flopy.modflow.ModflowDrt(m, stress_period_data={0:spd})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WESy-CY_EPP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BEWARE: This cell alone takes about 3.5 minutes to run\n",
        "\n",
        "# This cell ensures that no river cells are included in the drain package\n",
        "# If any river cells were added to the drain array, this code block will remove them\n",
        "\n",
        "ardrn_initial=len(ardrn)\n",
        "\n",
        "# Print the initial length of the drain array\n",
        "print('The initial length of the drain array is',ardrn_initial)\n",
        "\n",
        "for i in range(len(dfriv)-1):\n",
        "  for j in range(len(ardrn)-1):\n",
        "    if dfriv.loc[i,'row']==np.float64(ardrn[j][1]) and dfriv.loc[i,'col']==np.float64(ardrn[j][2]):\n",
        "      ardrn.remove(ardrn[j])\n",
        "\n",
        "ardrn_final=len(ardrn)\n",
        "\n",
        "# Print the final length of the drain array\n",
        "# The drain array should be 1500-2000 cells shorter than it was before\n",
        "print('The final length of the drain array is',ardrn_final)\n",
        "print(ardrn_initial-ardrn_final,'items were removed')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjX-o-4TEKS1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Put the drain data into a format that MODFLOW wants\n",
        "draindata={0:ardrn} #Here, \"draindata\" functions similarly to \"riverdata\" in the previous code block\n",
        "\n",
        "# Create the drn package\n",
        "drn = flopy.modflow.mfdrn.ModflowDrn(m, ipakcb=None, stress_period_data=draindata)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9AdhTraFBNW",
        "colab_type": "text"
      },
      "source": [
        "##3Fiv. Well Package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vWiKWm8vRtkE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#just some functions for processing json into model coordinates\n",
        "#nothing to see here... move along\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
        "\n",
        "def determine_layer(dtw, row, column, botgrids=botgrids, topgrid=topgrid):\n",
        "  depth = topgrid[int(row), int(column)] - dtw\n",
        "  if depth < botgrids[-1][int(row), int(column)]: return False\n",
        "  for i, elem in enumerate(botgrids):\n",
        "    nextelem = botgrids[(i + 1) % len(botgrids)][int(row), int(column)]\n",
        "    if depth < elem[int(row), int(column)] and depth > nextelem:  return i\n",
        "\n",
        "def convert_raw(well, maxrow=maxrow, maxcol=maxcol, ney=ney, swx=swx):\n",
        "  row, column = np.trunc((ney-well[1])/dy), np.trunc((well[2]-swx)/dx)\n",
        "  row -= 1\n",
        "  column -= 1\n",
        "  if row>=maxrow or row<0 or column>=maxcol or column<0:  return[False * 4]\n",
        "  elif well[0] == -999:  return [6, int(row), int(column), well[3]]\n",
        "  else: return [determine_layer(well[0], row, column), int(row), int(column), well[3]]\n",
        "\n",
        "def convert_to_LatLong(row, illimap = illimap, latlong = wgs84):\n",
        "  long, lat = pyproj.transform(illimap,latlong,row[2]/3.281, row[1]/3.281)\n",
        "  return [row[0], lat, long, row[3]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z189akc1QxTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!upload the processPumpData_SUMMER.json OR processPumpData_SPRING.json file from the ./pumping directory\n",
        "#make sure you've created them by running processPumpData.py\n",
        "\n",
        "#ensure the file you don't want to use is commented out\n",
        "#future iterations of this model will utilize multiple stress periods, and will not require file switching\n",
        "#to calibrate spring and summer pumpage, but client deadlines do not permit such major code refactoring\n",
        "#at this time...\n",
        "\n",
        "file_name = 'processPumpData_SUMMER.json'\n",
        "#file_name = 'processPumpData_SPRING.json'\n",
        "\n",
        "uploaded = files.upload() #Ah, I see you have the machine that goes 'ping!'.\n",
        "\n",
        "#if you get an error when running this cell for the first time\n",
        "#try rerunning this cell again\n",
        "\n",
        "lrcq = json.loads(uploaded[file_name].decode(\"utf-8\")) \n",
        "#This is my favourite. You see, we lease this back from the company we sold it to - \n",
        "#that way it comes under the monthly current budget and not the capital account.\n",
        "\n",
        "lrcq = {int(k):v for k,v in lrcq.items()}\n",
        "plot_points_df = pd.DataFrame(lrcq)\n",
        "\n",
        "lrcq.update({0:[convert_raw(x) for x in lrcq[0] if convert_raw(x)[0]]})\n",
        "\n",
        "wel = flopy.modflow.ModflowWel(model = m, stress_period_data=lrcq)\n",
        "\n",
        "del uploaded\n",
        "print(\"!WELLS SUCCESSFULLY ADDED TO MODEL!\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1_RgUD7hT3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#map of pumpage data\n",
        "\n",
        "\n",
        "\n",
        "fig=plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "#Define a projection\n",
        "ax = plt.axes(projection=ccrs.PlateCarree(central_longitude=0.0))\n",
        "#Define the spatial domain to plot\n",
        "ax.set_xlim(sw_long,ne_long) #The spatial domain spans from minimum longitude to maximum longitude (x-direction)\n",
        "ax.set_ylim(sw_lat,ne_lat) #The spatial domain spans from minimum latitude to maximum latitude (y-direction)\n",
        "#Define a title for the plot\n",
        "ax.set_title('Map of pumpage in region')\n",
        "\n",
        "#Using CartoPy, import several features from Natural Earth Data (see https://www.naturalearthdata.com/features/)\n",
        "#Large rivers:\n",
        "largerivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_lake_centerlines',\n",
        "    scale='110m', # major rivers\n",
        "    facecolor='none')\n",
        "#Small rivers:\n",
        "smallrivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_lake_centerlines_scale_rank',\n",
        "    scale='10m', # smaller rivers (still considered major by many/most people)\n",
        "    facecolor='none')\n",
        "#Smallest rivers:\n",
        "smallestrivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_north_america',\n",
        "    scale='10m',\n",
        "    facecolor='none')\n",
        "#Population centers:\n",
        "popplaces = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='urban_areas', # plots municipal boundaries\n",
        "    scale='10m',\n",
        "    facecolor='plum')\n",
        "#Major roads:\n",
        "majorroads = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='roads',\n",
        "    scale='10m',\n",
        "    facecolor='none')\n",
        "\n",
        "# Add the features defined above to the plot, with various colors and markers\n",
        "#ax.add_feature(popplaces,edgecolor='plum',linewidth=1.0) # Population centers will be light purple areas\n",
        "ax.add_feature(largerivers,edgecolor='aqua',linewidth=2.0) # Large, small, and smallest rivers will be light blue lines\n",
        "ax.add_feature(smallrivers,edgecolor='aqua',linewidth=1.5)\n",
        "ax.add_feature(smallestrivers,edgecolor='aqua',linewidth=1.0)\n",
        "#ax.add_feature(majorroads,edgecolor='gray',linewidth=1.0) #Roads will be thin gray lines\n",
        "ax.add_feature(USCOUNTIES.with_scale('5m'))\n",
        "\n",
        "for row in plot_points_df.iterrows():\n",
        "  ax.plot(convert_to_LatLong(row[1][0])[1], convert_to_LatLong(row[1][0])[2], marker='o', color = 'k', zorder = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAVD2sGT4oRb",
        "colab_type": "text"
      },
      "source": [
        "## 3G. Define output control"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NRhnNJU0TJhN",
        "colab": {}
      },
      "source": [
        "#create oc stress period data. \n",
        "spd = {(0, 0): ['print head', 'print budget', 'save head', 'save budget', 'save drawdown']}\n",
        "#create output control object\n",
        "oc = flopy.modflow.ModflowOc(model=m, stress_period_data=spd, compact=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD9BUXun4si5",
        "colab_type": "text"
      },
      "source": [
        "## 3H. Solver"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0tdHTKB-TMdU",
        "colab": {}
      },
      "source": [
        "# We will start by using the PCG solver with default settings\n",
        "#pcg = flopy.modflow.ModflowPcg(model=m)\n",
        "pcg = flopy.modflow.ModflowPcg(model=m,mxiter=200,iter1=50,hclose=1e-03,rclose=1e-03,relax=0.98,damp=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yMH7xi9_CF9",
        "colab_type": "text"
      },
      "source": [
        "## 3I. Plot model inputs (boundary conditions, elevations)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s6ZbnrHqTVjd",
        "colab": {}
      },
      "source": [
        "'''Plot grid and boundary conditions [without drains]'''\n",
        "#----------------------------------------------------------------------------\n",
        "plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "modelmap = flopy.plot.PlotMapView(model=m, layer=0)\n",
        "#grid = modelmap.plot_grid()\n",
        "ib = modelmap.plot_ibound()\n",
        "rvr = modelmap.plot_bc(ftype='RIV')\n",
        "wel = modelmap.plot_bc(ftype='WEL', plotAll = True)\n",
        "\n",
        "#add labels and legend\n",
        "plt.xlabel('Lx (ft)',fontsize = 14)\n",
        "plt.ylabel('Ly (ft)',fontsize = 14)\n",
        "plt.title('Boundary Conditions', fontsize = 15, fontweight = 'bold')\n",
        "plt.legend(handles=[mp.patches.Patch(color='blue',label='Const. Head',ec='black'),\n",
        "                    mp.patches.Patch(color='white',label='Active Cell',ec='black'),\n",
        "                    mp.patches.Patch(color='black',label='Inactive Cell',ec='black'),\n",
        "                    mp.patches.Patch(color='green',label='River',ec='green'),\n",
        "                    mp.patches.Patch(color='red',label='Well',ec='red')],\n",
        "                    bbox_to_anchor=(1.5,1.0))\n",
        "plt.show()\n",
        "#----------------------------------------------------------------------------"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r27l4dJK-Ksv",
        "colab": {}
      },
      "source": [
        "'''Plot Recharge'''\n",
        "#----------------------------------------------------------------------------\n",
        "plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "modelmap = flopy.plot.map.PlotMapView(model=m, layer=0) #use plotmapview to attach plot to model\n",
        "#contour_levels = np.linspace(400,800,41)\n",
        "#topelevations = modelmap.contour_array(topgrid, levels = contour_levels) #create head contours\n",
        "#plt.clabel(topelevations, inline=True,fontsize=12,fmt='%1.0f')\n",
        "\n",
        "#create colormap of named colors\n",
        "colors = [\"saddlebrown\",\"lightgoldenrodyellow\"]\n",
        "cmap = mp.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
        "norm = mp.colors.LogNorm(vmin=kf,vmax=kc)\n",
        "modelmap.plot_array(khlayers[0],norm = norm,cmap=cmap)\n",
        "rvr = modelmap.plot_bc(ftype='RIV')\n",
        "ib = modelmap.plot_ibound()\n",
        "#display parameters\n",
        "plt.xlabel('Lx (ft)',fontsize = 14)\n",
        "plt.ylabel('Ly (ft)',fontsize = 14)\n",
        "plt.title('Surficial Conductivity', fontsize = 15, fontweight = 'bold')\n",
        "plt.legend(handles=[mp.patches.Patch(color='saddlebrown',label='Low Conductivity',ec='saddlebrown'),\n",
        "                    mp.patches.Patch(color='white',label='Recharge=7.985E-4 ft/d',ec='white'),\n",
        "                    mp.patches.Patch(color='white',ec='white'),\n",
        "                    mp.patches.Patch(color='lightgoldenrodyellow',label='High Conductivity',ec='lightgoldenrodyellow'),\n",
        "                    mp.patches.Patch(color='white',label='Recharge=1.597E-3 ft/d',ec='white')],\n",
        "                    bbox_to_anchor=(1.5,1.0))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q40v753ZBEuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "modelmap = flopy.plot.map.PlotMapView(model=m, layer=0) #use plotmapview to attach plot to model\n",
        "#contour_levels = np.linspace(400,800,41)\n",
        "#topelevations = modelmap.contour_array(topgrid, levels = contour_levels) #create head contours\n",
        "#plt.clabel(topelevations, inline=True,fontsize=12,fmt='%1.0f')\n",
        "\n",
        "#create colormap  that works with both logarithmic scaling and normal scaling\n",
        "norm = mp.colors.LogNorm(vmin=Tmin,vmax=Tmax)\n",
        "#Plot options for normal/log plots\n",
        "#x = modelmap.plot_array(Total, norm = norm, cmap= 'plasma')\n",
        "x = modelmap.plot_array(Total, cmap= 'plasma')\n",
        "# model bounds\n",
        "rvr = modelmap.plot_bc(ftype='RIV')\n",
        "ib = modelmap.plot_ibound()\n",
        "\n",
        "#display parameters\n",
        "plt.xlabel('Lx (ft)',fontsize = 14)\n",
        "plt.ylabel('Ly (ft)',fontsize = 14)\n",
        "plt.colorbar(x)\n",
        "plt.title('Transmissivity [ft^2/day]', fontsize = 15, fontweight = 'bold')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Qxk16OXnVG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''Plot the boundary conditions'''\n",
        "#----------------------------------------------------------------------------\n",
        "# Be sure to verify that the drain cells work as intended:\n",
        "# - Check that the locations of drain cells in the map below (magenta) match the locations of low-k material at land surface in the map above (dark brown)\n",
        "# - Additionally, check that the river cells appear in the map below, to ensure that they were not overwritten as drain cells.\n",
        "\n",
        "plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "modelmap = flopy.plot.PlotMapView(model=m, layer=0)\n",
        "#grid = modelmap.plot_grid()\n",
        "ib = modelmap.plot_ibound()\n",
        "rvr = modelmap.plot_bc(ftype='RIV')\n",
        "drain = modelmap.plot_bc(ftype='DRN',color='magenta')\n",
        "wel = modelmap.plot_bc(ftype='WEL', plotAll = True)\n",
        "\n",
        "#add labels and legend\n",
        "plt.xlabel('Lx (ft)',fontsize = 14)\n",
        "plt.ylabel('Ly (ft)',fontsize = 14)\n",
        "plt.title('Boundary Conditions', fontsize = 15, fontweight = 'bold')\n",
        "plt.legend(handles=[mp.patches.Patch(color='green',label='River',ec='green'),\n",
        "                    mp.patches.Patch(color='magenta',label='Drain',ec='magenta'),\n",
        "                    mp.patches.Patch(color='red',label='Well',ec='red')],\n",
        "                    bbox_to_anchor=(1.5,1.0))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zhTGZRqqTUq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.array(khlayers).shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTWhw4UA-yK3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Plot representative cross section\n",
        "plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "modelxsect = flopy.plot.PlotCrossSection(model = m, line={\"row\":50}) #use plotmapview to attach plot to model\n",
        "#modelxsect = flopy.plot.PlotCrossSection(model = m, line={\"column\":100})\n",
        "#create colormap of named colors\n",
        "colors = [\"saddlebrown\",\"gray\",\"lightgoldenrodyellow\"]\n",
        "cmap = mp.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
        "norm = mp.colors.LogNorm(vmin=kf,vmax=kc)\n",
        "#modelxsect.plot_grid()\n",
        "khlaynp = np.array(khlayers)\n",
        "lines = modelxsect.plot_array(khlaynp,norm=norm, cmap=cmap)\n",
        "rvr = modelxsect.plot_bc(ftype='RIV')\n",
        "wel = modelxsect.plot_bc(ftype='WEL')\n",
        "modelxsect.plot_ibound()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4QPNEge41Mh",
        "colab_type": "text"
      },
      "source": [
        "# 4 Write and run the MODFLOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DH-U_oaiWTl8",
        "colab": {}
      },
      "source": [
        "# Write the model input\n",
        "m.write_input()\n",
        "# Execute the model run\n",
        "success, mfoutput = m.run_model(pause=False, report=True)\n",
        "# Report back if the model did not successfully complete\n",
        "if not success:\n",
        "    raise Exception('MODFLOW did not terminate normally.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bN2ivrtx_5yz",
        "colab_type": "text"
      },
      "source": [
        "# 5 Plot Output Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a7mhYeBVhDn6",
        "colab": {}
      },
      "source": [
        "'''Extract binary data from head and flow files'''\n",
        "#----------------------------------------------------------------------------\n",
        "#extract binary data from head file as flopy head object\n",
        "headobj = flopy.utils.binaryfile.HeadFile(modelname+'.hds')\n",
        "#extract head data from head object\n",
        "head = headobj.get_data(totim=1.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MZxuJhCzg_F8",
        "colab": {}
      },
      "source": [
        "'''Plot results'''\n",
        "#----------------------------------------------------------------------------\n",
        "plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "modelmap = flopy.plot.map.PlotMapView(model=m, layer=0) #use plotmapview to attach plot to model\n",
        "#grid = modelmap.plot_grid() #plot model grid\n",
        "#contour_levels = np.linspace(head[0].min(),head[0].max(),11) #set contour levels for contouring head\n",
        "contour_levels = np.linspace(200,1000,61) #set contour levels for contouring head\n",
        "head_contours = modelmap.contour_array(head[8], levels=contour_levels) #create head contours\n",
        "plt.clabel(head_contours, inline=True,fontsize=12,fmt='%1.0f')\n",
        "rvr = modelmap.plot_bc(ftype='RIV')\n",
        "\n",
        "#display parameters\n",
        "plt.xlabel('Lx (ft)',fontsize = 14)\n",
        "plt.ylabel('Ly (ft)',fontsize = 14)\n",
        "plt.title('Steady-State Model, Flow(ft^3/d) and Head(ft) Results', fontsize = 15, fontweight = 'bold')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mblTZE-3uOE_",
        "colab_type": "text"
      },
      "source": [
        "# 6 Model Calibration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpWgkEHYBBrS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import \"GRL_basic_info.csv\" and read in as a dataframe\n",
        "# Work-around due to issues importing the files from GitHub\n",
        "uploaded = files.upload()\n",
        "\n",
        "del uploaded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Diw4GjmTGRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import \"import_spring2019.csv\" and read in as a dataframe\n",
        "# Work-around due to issues importing the files from GitHub\n",
        "uploaded = files.upload()\n",
        "df_spring2019 = pd.read_csv('import_spring2019.csv',index_col=0)\n",
        "\n",
        "del uploaded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LygXcRdjvST",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import \"import_summer2019.csv\" and read in as a dataframe\n",
        "# Work-around due to issues importing the files from GitHub\n",
        "uploaded = files.upload()\n",
        "df_summer2019 = pd.read_csv('import_summer2019.csv',index_col=0)\n",
        "\n",
        "del uploaded"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v42De9BBD5G-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df_info\n",
        "\n",
        "# Read in \"GRL_basic_info.csv\" as a dataframe\n",
        "df_info = pd.read_csv('GRL_basic_info.csv',index_col=0)\n",
        "\n",
        "# Drop the row corresponding to the well with P-number 381671\n",
        "# This well has no measurements to which we can calibrate the model\n",
        "df_info=df_info.drop([381671])\n",
        "\n",
        "# Convert X_LAMBERT to column and Y_LAMBERT to row, and convert the new rows and columns to integers\n",
        "df_info['row'] = np.trunc((ney-df_info['Y_LAMBERT'])/dy)\n",
        "df_info['col'] = np.trunc((df_info['X_LAMBERT']-swx)/dx)\n",
        "df_info = df_info.astype({'row': int,'col': int})\n",
        "\n",
        "# trim the \"df_info\" dataframe to the model domain\n",
        "df_info = df_info.loc[df_info['X_LAMBERT']<nex]\n",
        "df_info = df_info.loc[df_info['Y_LAMBERT']<ney]\n",
        "df_info = df_info.loc[df_info['X_LAMBERT']>swx]\n",
        "df_info = df_info.loc[df_info['Y_LAMBERT']>swy]\n",
        "\n",
        "# Add in a column to \"df_info\" that includes the head at each well, as calculated by the model\n",
        "# These heads will be compared to the observed heads in the \"df_waterlevels\" dataframe\n",
        "df_info['head_calculated_ft']=np.nan\n",
        "\n",
        "# The following \"for\" loop fills in the \"head_calculated_ft\" column with the calculated head values from the model for each observation well\n",
        "for value in df_info.index:\n",
        "  # The following \"if / else if\" conditions identify the bottom-most layer of the model, for layers 4-9, where coarse material is located\n",
        "  # In other words, the following lines of code identify the deepest layer, between layers 4 and 9, that corresponds to the Sankoty aquifer\n",
        "  # The calculated heads for cells containing observation wells will be taken from this layer, in order to compare to the observed heads\n",
        "  if df_info.loc[value,'LOCAL_AQ_NAME']=='SANKOTY' and round(float(kl9[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 9\n",
        "    df_info.at[value,'head_calculated_ft'] = head[8][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='SANKOTY' and round(float(kl8[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 8\n",
        "    df_info.at[value,'head_calculated_ft'] = head[7][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='SANKOTY' and round(float(kl7[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 7\n",
        "    df_info.at[value,'head_calculated_ft'] = head[6][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='SANKOTY' and round(float(kl6[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 6\n",
        "    df_info.at[value,'head_calculated_ft'] = head[5][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='SANKOTY' and round(float(kl5[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 5\n",
        "    df_info.at[value,'head_calculated_ft'] = head[4][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='SANKOTY' and round(float(kl4[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 4\n",
        "    df_info.at[value,'head_calculated_ft'] = head[3][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='SANKOTY':  # Contingency case: if no cells are found that correspond to the Sankoty aquifer, layer 9 is used.\n",
        "                                                        # This case signals a limitation of our model.  Specifically, our cross-sections do not capture the presence of coarse material corresponding to the Sankoty aquifer at the location of an observation well, where coarse material must exist.\n",
        "    df_info.at[value,'head_calculated_ft'] = head[8][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  \n",
        "  # The following \"if / else if\" conditions identify the bottom-most layer of the model, for layers 1-3, where coarse material is located\n",
        "  # In other words, the following lines of code identify the deepest layer, between layers 1 and 3, that corresponds to the Tampico aquifer\n",
        "  # The calculated heads for cells containing observation wells will be taken from this layer, in order to compare to the observed heads\n",
        "  if df_info.loc[value,'LOCAL_AQ_NAME']=='TAMPICO' and round(float(kl3[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 3\n",
        "    df_info.at[value,'head_calculated_ft'] = head[2][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='TAMPICO' and round(float(kl2[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 2\n",
        "    df_info.at[value,'head_calculated_ft'] = head[1][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='TAMPICO' and round(float(kl1[df_info.loc[value,'row']][df_info.loc[value,'col']]),5)==kf: #Layer 1\n",
        "    df_info.at[value,'head_calculated_ft'] = head[0][df_info.loc[value,'row']][df_info.loc[value,'col']]\n",
        "  elif df_info.loc[value,'LOCAL_AQ_NAME']=='TAMPICO':  # Contingency case: if no cells are found that correspond to the Tampico aquifer, layer 3 is used.\n",
        "                                                        # This case signals a limitation of our model.  Specifically, our cross-sections do not capture the presence of coarse material corresponding to the Tampico aquifer at the location of an observation well, where coarse material must exist.\n",
        "    df_info.at[value,'head_calculated_ft'] = head[2][df_info.loc[value,'row']][df_info.loc[value,'col']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PztieXLsLVyX",
        "colab_type": "text"
      },
      "source": [
        "### Calibration for Spring 2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCrYMgkEUxCd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calibration for Spring 2019\n",
        "# Make sure SPRING wells are used\n",
        "\n",
        "# Create a new column in the \"df_info\" dataframe for observed heads from Summer 2019\n",
        "df_info['head_spring2019_ft']=np.nan\n",
        "\n",
        "# Change the NaN values in the new column to the observed head values, obtained from the imported \"df_summer2019\" dataframe\n",
        "for value in df_info.index:\n",
        "  df_info.at[value,'head_spring2019_ft'] = df_spring2019.loc[value,'Water_Surface_Elevation']\n",
        "\n",
        "# Plot the calculated and observed values for comparison\n",
        "plt.scatter(df_info.head_spring2019_ft, df_info.head_calculated_ft)\n",
        "plt.plot(df_info.head_spring2019_ft,df_info.head_spring2019_ft)\n",
        "\n",
        "one_to_one = mp.lines.Line2D(df_info.head_spring2019_ft,df_info.head_spring2019_ft, label='1 to 1 Line')\n",
        "\n",
        "plt.xlabel('Observed Water Level (ft)')\n",
        "plt.ylabel('Calculated Water Level (ft)')\n",
        "plt.legend(handles=[one_to_one])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWQddruqLcpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the RMS error\n",
        "df_info['diff^2_ft']=(df_info.head_calculated_ft-df_info.head_spring2019_ft)**2 # Create a new column in \"df_info\", containing the differences squared between the calculated and observed head values\n",
        "RMS=math.sqrt(np.mean(df_info['diff^2_ft']))# Calculate the RMS error as the square root of the average of the new \"diff^2_ft\" column\n",
        "print('The RMS error was calculated to be',RMS)\n",
        "\n",
        "# Create a new column in the \"df_info\" dataframe containing the calculated error for each observation well\n",
        "# Positive error means the model head is too low (not enough water)\n",
        "# Negative error means the model head is too high (too much water)\n",
        "df_info['error']=df_info['head_spring2019_ft']-df_info['head_calculated_ft']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTvSifxCMVxI",
        "colab_type": "text"
      },
      "source": [
        "### Calibration for Summer 2019"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpOZcrL_ksaI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calibration for Summer 2019\n",
        "# Make sure SUMMER wells are used\n",
        "\n",
        "# Create a new column in the \"df_info\" dataframe for observed heads from Summer 2019\n",
        "df_info['head_summer2019_ft']=np.nan\n",
        "\n",
        "# Change the NaN values in the new column to the observed head values, obtained from the imported \"df_summer2019\" dataframe\n",
        "for value in df_info.index:\n",
        "  df_info.at[value,'head_summer2019_ft'] = df_summer2019.loc[value,'Water_Surface_Elevation']\n",
        "\n",
        "# Plot the calculated and observed values for comparison\n",
        "plt.scatter(df_info.head_summer2019_ft, df_info.head_calculated_ft)\n",
        "plt.plot(df_info.head_summer2019_ft, df_info.head_summer2019_ft)\n",
        "\n",
        "one_to_one = mp.lines.Line2D(df_info.head_summer2019_ft,df_info.head_summer2019_ft, label='1 to 1 Line')\n",
        "\n",
        "plt.xlabel('Observed Water Level (ft)')\n",
        "plt.ylabel('Calculated Water Level (ft)')\n",
        "plt.legend(handles=[one_to_one])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mouHY8d6FN1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Calculate the RMS error\n",
        "df_info['diff^2_ft']=(df_info.head_calculated_ft-df_info.head_summer2019_ft)**2 # Create a new column in \"df_info\", containing the differences squared between the calculated and observed head values\n",
        "RMS=math.sqrt(np.mean(df_info['diff^2_ft']))# Calculate the RMS error as the square root of the average of the new \"diff^2_ft\" column\n",
        "print('The RMS error was calculated to be',RMS)\n",
        "\n",
        "# Create a new column in the \"df_info\" dataframe containing the calculated error for each observation well\n",
        "# Positive error means the model head is too low (not enough water)\n",
        "# Negative error means the model head is too high (too much water)\n",
        "df_info['error']=df_info['head_summer2019_ft']-df_info['head_calculated_ft']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is2kJb95Lpa0",
        "colab_type": "text"
      },
      "source": [
        "### Plot the calculated error on a map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_xbNnZmL79v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Note that the code blocks below will pull the data for whichever scenario was simulated, summer or spring"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSXaHFH0FPxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Define the area over which to plot data\n",
        "\n",
        "#Conduct the Universal Kriging, for the most recent data point\n",
        "#The summer 2019 data will be addressed later\n",
        "UK = UniversalKriging(df_info['LONG_WGS_84'], df_info['LAT_WGS_84'],df_info['error'], variogram_model='spherical',nlags=6)\n",
        "\n",
        "#Create xpoints and ypoints in space, with 0.01 spacing\n",
        "xpoints = np.arange(sw_long,ne_long,0.01)\n",
        "ypoints = np.arange(sw_lat,ne_lat,0.01)\n",
        "\n",
        "# create a meshgrid with xpoints and ypoints, to be used later in the code\n",
        "X,Y = np.meshgrid(xpoints,ypoints)\n",
        "\n",
        "# calculate the interpolated grid and fill values.\n",
        "z, var = UK.execute('grid', xpoints, ypoints)\n",
        "z = z.filled(fill_value=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-ONZ9MtFRdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Create a figure\n",
        "fig=plt.figure(figsize=(10,10)) #create 10 x 10 figure\n",
        "#Define a projection\n",
        "ax = plt.axes(projection=ccrs.PlateCarree())\n",
        "#Define the spatial domain to plot\n",
        "ax.set_xlim(sw_long,ne_long) #The spatial domain spans from minimum longitude to maximum longitude (x-direction)\n",
        "ax.set_ylim(sw_lat,ne_lat) #The spatial domain spans from minimum longitude to maximum latitude (y-direction)\n",
        "#Define a title for the plot\n",
        "ax.set_title('Calculated error (ft difference) over the model area')\n",
        "\n",
        "#Using CartoPy, import several features from Natural Earth Data (see https://www.naturalearthdata.com/features/)\n",
        "#Large rivers:\n",
        "largerivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_lake_centerlines',\n",
        "    scale='110m', # major rivers\n",
        "    facecolor='none')\n",
        "#Small rivers:\n",
        "smallrivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_lake_centerlines_scale_rank',\n",
        "    scale='10m', # smaller rivers (still considered major by many/most people)\n",
        "    facecolor='none')\n",
        "#Smallest rivers:\n",
        "smallestrivers = cf.NaturalEarthFeature(\n",
        "    category='physical',\n",
        "    name='rivers_north_america',\n",
        "    scale='10m',\n",
        "    facecolor='none')\n",
        "#Population centers:\n",
        "popplaces = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='urban_areas', # plots municipal boundaries\n",
        "    scale='10m',\n",
        "    facecolor='plum')\n",
        "#Major roads:\n",
        "majorroads = cf.NaturalEarthFeature(\n",
        "    category='cultural',\n",
        "    name='roads',\n",
        "    scale='10m',\n",
        "    facecolor='none')\n",
        "\n",
        "# Add the features defined above to the plot, with various colors and markers\n",
        "ax.add_feature(popplaces,edgecolor='plum',linewidth=1.0) # Population centers will be light purple areas\n",
        "ax.add_feature(largerivers,edgecolor='aqua',linewidth=2.0) # Large, small, and smallest rivers will be light blue lines\n",
        "ax.add_feature(smallrivers,edgecolor='aqua',linewidth=2.0)\n",
        "ax.add_feature(smallestrivers,edgecolor='aqua',linewidth=2.0)\n",
        "ax.add_feature(majorroads,edgecolor='gray',linewidth=1.0) #Roads will be thin gray lines\n",
        "ax.add_feature(USCOUNTIES.with_scale('5m'))\n",
        "\n",
        "#Create contours from the interpolation\n",
        "error_contour_levels = [-60,-45,-30,-15,0,15,30,45,60,75] # Set contour levels for contouring error, use this line for summer\n",
        "#error_contour_levels = [-80,-70,-60,-50,-40,-30,-20,-10,0,10] # Set contour levels for contouring error, use this line for spring\n",
        "cset_contour = plt.contour(X,Y,z,error_contour_levels,colors='blue')\n",
        "\n",
        "#Add in a continuous color flood\n",
        "#cset_fill=plt.imshow(z,vmin=-100,vmax=100,cmap=plt.cm.coolwarm,origin='lower',extent=[X.min(), X.max(), Y.min(), Y.max()])\n",
        "cset_fill=plt.imshow(z,vmin=-100,vmax=100,cmap=plt.cm.coolwarm,origin='lower',extent=[X.min(), X.max(), Y.min(), Y.max()])\n",
        "\n",
        "#The following code could also be used, if a discrete color flood is preferred:\n",
        "#cset_fill = plt.contourf(X,Y,z,vmin=-100,vmax=100,cmap=plt.cm.coolwarm)\n",
        "\n",
        "#Label contours (makes use of pylab)\n",
        "pylab.clabel(cset_contour, inline=1, fontsize=10,fmt='%1.0f')\n",
        "\n",
        "#Plot the points that were measured\n",
        "points=plt.scatter(df_info['LONG_WGS_84'], df_info['LAT_WGS_84'], marker=\".\", color=\"black\", label=\"Data Points\")\n",
        "\n",
        "#Add a legend to the plot\n",
        "cities_towns=mpatches.Patch(color='plum',label='Population Centers') #Here I create a proxy artist to represent population centers on the legend\n",
        "rivers=mlines.Line2D([],[],linewidth=2.0,color='aqua',label='Rivers') #Proxy artist for large and small rivers\n",
        "roads=mlines.Line2D([],[],linewidth=1.0,color='gray',label='Roads') #Proxy artist for major roads\n",
        "ax.legend(loc='lower left',handles=[cities_towns,points,rivers,roads])\n",
        "\n",
        "#Add in a colorbar\n",
        "cax = fig.add_axes([0.34, 0.32, 0.25, 0.03])\n",
        "fig.colorbar(cset_fill, cax=cax, orientation='horizontal')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlD4gXdIOEdw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_info.error.min()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UlnPQbfOHc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_info.error.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltTkMHry04jS",
        "colab_type": "text"
      },
      "source": [
        "# 7 Calculate Discharge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpJw5gSs08FB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# first of all, read my_model.list file (this contains the information taht we need for discharge)\n",
        "# the budget is returned as recarray\n",
        "from flopy.utils import mflistfile\n",
        "mf_list = mflistfile.MfusgListBudget(\"my_model.list\")\n",
        "budget = mf_list.get_cumulative()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBNHC74RIcYT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert the recarray to pandas dataframe\n",
        "data = pd.DataFrame(budget)\n",
        "# print(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXBw_ZGa_uJx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the river leakage out minus in to calculate the discharge at current situation (summer 2019)\n",
        "discharge_current = int(data['RIVER_LEAKAGE_OUT'] - data['RIVER_LEAKAGE_IN'])  #ft3/day\n",
        "print('The discharge of current situation is', discharge_current, 'ft3/day.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cu5EKbImP8o8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discharge_pre is the discharge of pre-development where there's no pumping\n",
        "# I use the same method as above to calculate this at a different file and copy paste the result here\n",
        "discharge_pre = 38593780 #ft3/day\n",
        "discharge_diff = discharge_pre - discharge_current\n",
        "print('The reduction in natural groundwater discharge is', discharge_diff, 'ft3/day.')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}